{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruamel.yaml as yaml\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import altair as alt\n",
    "alt.themes.enable('opaque')\n",
    "\n",
    "\n",
    "NO_CONFIG_ERR_MSG = \"\"\"No config file found. Root directory is determined by presence of \"config.yaml\" file.\"\"\"\n",
    "\n",
    "original_wd = os.getcwd()\n",
    "\n",
    "# Number of times to move back in directory\n",
    "num_retries = 10\n",
    "for x in range(0, num_retries):\n",
    "    # try to load config file\n",
    "    try:\n",
    "        with open(\"config.yaml\", 'r') as stream:\n",
    "            cfg = yaml.safe_load(stream)\n",
    "    # If not found move back one directory level\n",
    "    except FileNotFoundError:\n",
    "        os.chdir('../')\n",
    "        # If reached the max number of directory levels change to original wd and print error msg\n",
    "        if x+1 == num_retries:\n",
    "            os.chdir(original_wd)\n",
    "            print(NO_CONFIG_ERR_MSG)\n",
    "\n",
    "# Add directory to PATH\n",
    "path = os.getcwd()\n",
    "\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "madelon_df = pd.read_hdf('data/processed/datasets.hdf', 'madelon', complib='blosc', complevel=9)\n",
    "\n",
    "# Uncomment hdf to use process text (i.e. no Rings)\n",
    "abalone_df = pd.read_hdf('data/processed/datasets.hdf', 'abalone', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Discussion: Algorithms Analysis\n",
    "    * For each algorithm: \n",
    "        * Train/Test Error Rates\n",
    "            * At the end if there's enough time, might want to add\n",
    "            precision, recall, f1 score as metrics on best hyper param models\n",
    "        * Training Time\n",
    "        * Learning Rate\n",
    "        * 'Overfitting' Curves (Expressiveness)\n",
    "        * Hyperparameter Analysis\n",
    "            * Why did these come out the best? \n",
    "            Discuss what each parameter does and reasoning for why that performed best. \n",
    "            Look at Grid search results if possible to see if distribution of params change \n",
    "            the outcome much (i.e. the effect of param on performance)\n",
    "\n",
    "\n",
    "\n",
    "#### Artificial Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas:\n",
    "\n",
    "Best Params --> Justification\n",
    "\n",
    "Columns\n",
    "\n",
    "* LC, Complexity Curve, and OF curve as columns in Altair plot\n",
    "\n",
    "Rows\n",
    "\n",
    "* Datasets\n",
    "\n",
    "Color\n",
    "\n",
    "* Train Test\n",
    "\n",
    "Facet Plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANN_abalone_LC_test.csv',\n",
       " 'ANN_abalone_LC_train.csv',\n",
       " 'ANN_abalone_reg.csv',\n",
       " 'ANN_abalone_timing.csv',\n",
       " 'ITERtestSET_ANN_abalone.csv',\n",
       " 'ITERtestSET_ANN_OF_abalone.csv',\n",
       " 'ITER_base_ANN_abalone.csv',\n",
       " 'ITER_base_ANN_OF_abalone.csv']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET = 'abalone'\n",
    "ALGORITHM = 'ANN'\n",
    "from pathlib import Path\n",
    "RESULTS_PATH = Path('reports/output')\n",
    "\n",
    "# Loop through and find relevant files\n",
    "relevant_files = []\n",
    "for file in os.listdir(RESULTS_PATH):\n",
    "    #print(file)\n",
    "    fname_split = file.split(\"_\")\n",
    "    # Split last string on extension\n",
    "    file_ext = fname_split.pop()\n",
    "    fname_split = fname_split + file_ext.split('.')\n",
    "    #print(fname_split)\n",
    "    if (DATASET in fname_split) & (ALGORITHM in fname_split):\n",
    "        relevant_files.append(file)\n",
    "relevant_files        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ANN_madelon_LC_test', 'ANN_madelon_LC_train', 'ANN_madelon_reg', 'ANN_madelon_timing', 'ITERtestSET_ANN_madelon', 'ITERtestSET_ANN_OF_madelon', 'ITER_base_ANN_madelon', 'ITER_base_ANN_OF_madelon'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_df_dict_from_algorithm_dataset(directory_path, dataset=None, \n",
    "                                       algorithm=None):\n",
    "    \n",
    "    from pathlib import Path\n",
    "    results_path = Path(directory_path)\n",
    "\n",
    "    # Loop through and find relevant files\n",
    "    relevant_files = []\n",
    "    # Dictionary to hold relevant files\n",
    "    df_dict = {}\n",
    "    \n",
    "    for file in os.listdir(results_path):\n",
    "        fname_split = file.split(\"_\")\n",
    "        # Split last string on extension\n",
    "        file_ext = fname_split.pop()\n",
    "        fname_split = fname_split + file_ext.split('.')\n",
    "        #print(fname_split)\n",
    "        if (dataset in fname_split) & (algorithm in fname_split):\n",
    "            relevant_files.append(file)\n",
    "            \n",
    "    for fname in relevant_files:\n",
    "        key = fname.split('.')[0]\n",
    "        df_dict[key] = pd.read_csv(RESULTS_PATH / fname)        \n",
    "            \n",
    "    return df_dict\n",
    "test_df_dict = get_df_dict_from_algorithm_dataset('reports/output/', algorithm='ANN', dataset='madelon')\n",
    "test_df_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Best Params for each algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Score</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>{'MLP__activation': 'relu'</td>\n",
       "      <td>'MLP__alpha': 0.0001</td>\n",
       "      <td>'MLP__hidden_layer_sizes': (62</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.621138</td>\n",
       "      <td>{'MLP__activation': 'relu'</td>\n",
       "      <td>'MLP__alpha': 1.0</td>\n",
       "      <td>'MLP__hidden_layer_sizes': (20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boost</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>{'Boost__base_estimator__alpha': -0.001</td>\n",
       "      <td>'Boost__n_estimators': 5}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boost</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.628263</td>\n",
       "      <td>{'Boost__base_estimator__alpha': 0.03162277660...</td>\n",
       "      <td>'Boost__n_estimators': 20}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>{'DT__alpha': 0</td>\n",
       "      <td>'DT__class_weight': 'balanced'</td>\n",
       "      <td>'DT__criterion': 'gini'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.618223</td>\n",
       "      <td>{'DT__alpha': 0.01</td>\n",
       "      <td>'DT__class_weight': 'balanced'</td>\n",
       "      <td>'DT__criterion': 'gini'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.864103</td>\n",
       "      <td>{'KNN__metric': 'manhattan'</td>\n",
       "      <td>'KNN__n_neighbors': 10</td>\n",
       "      <td>'KNN__weights': 'distance'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.628263</td>\n",
       "      <td>{'KNN__metric': 'chebyshev'</td>\n",
       "      <td>'KNN__n_neighbors': 34</td>\n",
       "      <td>'KNN__weights': 'distance'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM_Lin</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.601282</td>\n",
       "      <td>{'SVM__alpha': 0.1</td>\n",
       "      <td>'SVM__n_iter': 687}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM_Lin</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.622048</td>\n",
       "      <td>{'SVM__alpha': 0.0001</td>\n",
       "      <td>'SVM__n_iter': 428}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.837179</td>\n",
       "      <td>{'SVM__alpha': 0.00031622776601683794</td>\n",
       "      <td>'SVM__gamma_frac': 0.15000000000000002</td>\n",
       "      <td>'SVM__n_iter': 687}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.633860</td>\n",
       "      <td>{'SVM__alpha': 0.0031622776601683794</td>\n",
       "      <td>'SVM__gamma_frac': 0.2</td>\n",
       "      <td>'SVM__n_iter': 428}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Algorithm  Dataset     Score  \\\n",
       "0        ANN  madelon  0.762821   \n",
       "1        ANN  abalone  0.621138   \n",
       "2      Boost  madelon  0.826923   \n",
       "3      Boost  abalone  0.628263   \n",
       "4         DT  madelon  0.810256   \n",
       "5         DT  abalone  0.618223   \n",
       "6        KNN  madelon  0.864103   \n",
       "7        KNN  abalone  0.628263   \n",
       "8    SVM_Lin  madelon  0.601282   \n",
       "9    SVM_Lin  abalone  0.622048   \n",
       "10   SVM_RBF  madelon  0.837179   \n",
       "11   SVM_RBF  abalone  0.633860   \n",
       "\n",
       "                                      Hyperparameters  \\\n",
       "0                          {'MLP__activation': 'relu'   \n",
       "1                          {'MLP__activation': 'relu'   \n",
       "2             {'Boost__base_estimator__alpha': -0.001   \n",
       "3   {'Boost__base_estimator__alpha': 0.03162277660...   \n",
       "4                                     {'DT__alpha': 0   \n",
       "5                                  {'DT__alpha': 0.01   \n",
       "6                         {'KNN__metric': 'manhattan'   \n",
       "7                         {'KNN__metric': 'chebyshev'   \n",
       "8                                  {'SVM__alpha': 0.1   \n",
       "9                               {'SVM__alpha': 0.0001   \n",
       "10              {'SVM__alpha': 0.00031622776601683794   \n",
       "11               {'SVM__alpha': 0.0031622776601683794   \n",
       "\n",
       "                                 Unnamed: 4                       Unnamed: 5  \\\n",
       "0                      'MLP__alpha': 0.0001   'MLP__hidden_layer_sizes': (62   \n",
       "1                         'MLP__alpha': 1.0   'MLP__hidden_layer_sizes': (20   \n",
       "2                 'Boost__n_estimators': 5}                              NaN   \n",
       "3                'Boost__n_estimators': 20}                              NaN   \n",
       "4            'DT__class_weight': 'balanced'         'DT__criterion': 'gini'}   \n",
       "5            'DT__class_weight': 'balanced'         'DT__criterion': 'gini'}   \n",
       "6                    'KNN__n_neighbors': 10      'KNN__weights': 'distance'}   \n",
       "7                    'KNN__n_neighbors': 34      'KNN__weights': 'distance'}   \n",
       "8                       'SVM__n_iter': 687}                              NaN   \n",
       "9                       'SVM__n_iter': 428}                              NaN   \n",
       "10   'SVM__gamma_frac': 0.15000000000000002              'SVM__n_iter': 687}   \n",
       "11                   'SVM__gamma_frac': 0.2              'SVM__n_iter': 428}   \n",
       "\n",
       "    Unnamed: 6 Unnamed: 7  \n",
       "0         62.0       62)}  \n",
       "1         20.0       20)}  \n",
       "2          NaN        NaN  \n",
       "3          NaN        NaN  \n",
       "4          NaN        NaN  \n",
       "5          NaN        NaN  \n",
       "6          NaN        NaN  \n",
       "7          NaN        NaN  \n",
       "8          NaN        NaN  \n",
       "9          NaN        NaN  \n",
       "10         NaN        NaN  \n",
       "11         NaN        NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('reports/output/test-results-reduced.csv')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collapsing Hyperparameters into the one column\n",
    "\n",
    "    1) From 'Hyperparameters' column on turn them into strings\n",
    "    2) Sum across the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Best_Params'] = results.loc[:, 'Hyperparameters':].astype(str).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Score</th>\n",
       "      <th>Hyperparameters</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>{'MLP__activation': 'relu'</td>\n",
       "      <td>'MLP__alpha': 0.0001</td>\n",
       "      <td>'MLP__hidden_layer_sizes': (62</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62)}</td>\n",
       "      <td>{'MLP__activation': 'relu' 'MLP__alpha': 0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.621138</td>\n",
       "      <td>{'MLP__activation': 'relu'</td>\n",
       "      <td>'MLP__alpha': 1.0</td>\n",
       "      <td>'MLP__hidden_layer_sizes': (20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20)}</td>\n",
       "      <td>{'MLP__activation': 'relu' 'MLP__alpha': 1.0 '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Boost</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.826923</td>\n",
       "      <td>{'Boost__base_estimator__alpha': -0.001</td>\n",
       "      <td>'Boost__n_estimators': 5}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Boost__base_estimator__alpha': -0.001 'Boost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boost</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.628263</td>\n",
       "      <td>{'Boost__base_estimator__alpha': 0.03162277660...</td>\n",
       "      <td>'Boost__n_estimators': 20}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Boost__base_estimator__alpha': 0.03162277660...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.810256</td>\n",
       "      <td>{'DT__alpha': 0</td>\n",
       "      <td>'DT__class_weight': 'balanced'</td>\n",
       "      <td>'DT__criterion': 'gini'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'DT__alpha': 0 'DT__class_weight': 'balanced'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DT</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.618223</td>\n",
       "      <td>{'DT__alpha': 0.01</td>\n",
       "      <td>'DT__class_weight': 'balanced'</td>\n",
       "      <td>'DT__criterion': 'gini'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'DT__alpha': 0.01 'DT__class_weight': 'balanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.864103</td>\n",
       "      <td>{'KNN__metric': 'manhattan'</td>\n",
       "      <td>'KNN__n_neighbors': 10</td>\n",
       "      <td>'KNN__weights': 'distance'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'KNN__metric': 'manhattan' 'KNN__n_neighbors'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.628263</td>\n",
       "      <td>{'KNN__metric': 'chebyshev'</td>\n",
       "      <td>'KNN__n_neighbors': 34</td>\n",
       "      <td>'KNN__weights': 'distance'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'KNN__metric': 'chebyshev' 'KNN__n_neighbors'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM_Lin</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.601282</td>\n",
       "      <td>{'SVM__alpha': 0.1</td>\n",
       "      <td>'SVM__n_iter': 687}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'SVM__alpha': 0.1 'SVM__n_iter': 687}nannannan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM_Lin</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.622048</td>\n",
       "      <td>{'SVM__alpha': 0.0001</td>\n",
       "      <td>'SVM__n_iter': 428}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'SVM__alpha': 0.0001 'SVM__n_iter': 428}nanna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>madelon</td>\n",
       "      <td>0.837179</td>\n",
       "      <td>{'SVM__alpha': 0.00031622776601683794</td>\n",
       "      <td>'SVM__gamma_frac': 0.15000000000000002</td>\n",
       "      <td>'SVM__n_iter': 687}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'SVM__alpha': 0.00031622776601683794 'SVM__ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM_RBF</td>\n",
       "      <td>abalone</td>\n",
       "      <td>0.633860</td>\n",
       "      <td>{'SVM__alpha': 0.0031622776601683794</td>\n",
       "      <td>'SVM__gamma_frac': 0.2</td>\n",
       "      <td>'SVM__n_iter': 428}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'SVM__alpha': 0.0031622776601683794 'SVM__gam...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Algorithm  Dataset     Score  \\\n",
       "0        ANN  madelon  0.762821   \n",
       "1        ANN  abalone  0.621138   \n",
       "2      Boost  madelon  0.826923   \n",
       "3      Boost  abalone  0.628263   \n",
       "4         DT  madelon  0.810256   \n",
       "5         DT  abalone  0.618223   \n",
       "6        KNN  madelon  0.864103   \n",
       "7        KNN  abalone  0.628263   \n",
       "8    SVM_Lin  madelon  0.601282   \n",
       "9    SVM_Lin  abalone  0.622048   \n",
       "10   SVM_RBF  madelon  0.837179   \n",
       "11   SVM_RBF  abalone  0.633860   \n",
       "\n",
       "                                      Hyperparameters  \\\n",
       "0                          {'MLP__activation': 'relu'   \n",
       "1                          {'MLP__activation': 'relu'   \n",
       "2             {'Boost__base_estimator__alpha': -0.001   \n",
       "3   {'Boost__base_estimator__alpha': 0.03162277660...   \n",
       "4                                     {'DT__alpha': 0   \n",
       "5                                  {'DT__alpha': 0.01   \n",
       "6                         {'KNN__metric': 'manhattan'   \n",
       "7                         {'KNN__metric': 'chebyshev'   \n",
       "8                                  {'SVM__alpha': 0.1   \n",
       "9                               {'SVM__alpha': 0.0001   \n",
       "10              {'SVM__alpha': 0.00031622776601683794   \n",
       "11               {'SVM__alpha': 0.0031622776601683794   \n",
       "\n",
       "                                 Unnamed: 4                       Unnamed: 5  \\\n",
       "0                      'MLP__alpha': 0.0001   'MLP__hidden_layer_sizes': (62   \n",
       "1                         'MLP__alpha': 1.0   'MLP__hidden_layer_sizes': (20   \n",
       "2                 'Boost__n_estimators': 5}                              NaN   \n",
       "3                'Boost__n_estimators': 20}                              NaN   \n",
       "4            'DT__class_weight': 'balanced'         'DT__criterion': 'gini'}   \n",
       "5            'DT__class_weight': 'balanced'         'DT__criterion': 'gini'}   \n",
       "6                    'KNN__n_neighbors': 10      'KNN__weights': 'distance'}   \n",
       "7                    'KNN__n_neighbors': 34      'KNN__weights': 'distance'}   \n",
       "8                       'SVM__n_iter': 687}                              NaN   \n",
       "9                       'SVM__n_iter': 428}                              NaN   \n",
       "10   'SVM__gamma_frac': 0.15000000000000002              'SVM__n_iter': 687}   \n",
       "11                   'SVM__gamma_frac': 0.2              'SVM__n_iter': 428}   \n",
       "\n",
       "    Unnamed: 6 Unnamed: 7                                        Best_Params  \n",
       "0         62.0       62)}  {'MLP__activation': 'relu' 'MLP__alpha': 0.000...  \n",
       "1         20.0       20)}  {'MLP__activation': 'relu' 'MLP__alpha': 1.0 '...  \n",
       "2          NaN        NaN  {'Boost__base_estimator__alpha': -0.001 'Boost...  \n",
       "3          NaN        NaN  {'Boost__base_estimator__alpha': 0.03162277660...  \n",
       "4          NaN        NaN  {'DT__alpha': 0 'DT__class_weight': 'balanced'...  \n",
       "5          NaN        NaN  {'DT__alpha': 0.01 'DT__class_weight': 'balanc...  \n",
       "6          NaN        NaN  {'KNN__metric': 'manhattan' 'KNN__n_neighbors'...  \n",
       "7          NaN        NaN  {'KNN__metric': 'chebyshev' 'KNN__n_neighbors'...  \n",
       "8          NaN        NaN    {'SVM__alpha': 0.1 'SVM__n_iter': 687}nannannan  \n",
       "9          NaN        NaN  {'SVM__alpha': 0.0001 'SVM__n_iter': 428}nanna...  \n",
       "10         NaN        NaN  {'SVM__alpha': 0.00031622776601683794 'SVM__ga...  \n",
       "11         NaN        NaN  {'SVM__alpha': 0.0031622776601683794 'SVM__gam...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "background": "white",
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-f36743b896d3ba9bf089f85a6ef93a94"
       },
       "datasets": {
        "data-f36743b896d3ba9bf089f85a6ef93a94": [
         {
          "Algorithm": "ANN",
          "Best_Params": "{'MLP__activation': 'relu' 'MLP__alpha': 0.0001 'MLP__hidden_layer_sizes': (6262.0 62)}",
          "Dataset": "madelon",
          "Hyperparameters": "{'MLP__activation': 'relu'",
          "Score": 0.762820513,
          "Unnamed: 4": " 'MLP__alpha': 0.0001",
          "Unnamed: 5": " 'MLP__hidden_layer_sizes': (62",
          "Unnamed: 6": 62,
          "Unnamed: 7": " 62)}"
         },
         {
          "Algorithm": "ANN",
          "Best_Params": "{'MLP__activation': 'relu' 'MLP__alpha': 1.0 'MLP__hidden_layer_sizes': (2020.0 20)}",
          "Dataset": "abalone",
          "Hyperparameters": "{'MLP__activation': 'relu'",
          "Score": 0.621137929,
          "Unnamed: 4": " 'MLP__alpha': 1.0",
          "Unnamed: 5": " 'MLP__hidden_layer_sizes': (20",
          "Unnamed: 6": 20,
          "Unnamed: 7": " 20)}"
         },
         {
          "Algorithm": "Boost",
          "Best_Params": "{'Boost__base_estimator__alpha': -0.001 'Boost__n_estimators': 5}nannannan",
          "Dataset": "madelon",
          "Hyperparameters": "{'Boost__base_estimator__alpha': -0.001",
          "Score": 0.826923077,
          "Unnamed: 4": " 'Boost__n_estimators': 5}",
          "Unnamed: 5": null,
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "Boost",
          "Best_Params": "{'Boost__base_estimator__alpha': 0.0316227766016838 'Boost__n_estimators': 20}nannannan",
          "Dataset": "abalone",
          "Hyperparameters": "{'Boost__base_estimator__alpha': 0.0316227766016838",
          "Score": 0.628263286,
          "Unnamed: 4": " 'Boost__n_estimators': 20}",
          "Unnamed: 5": null,
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "DT",
          "Best_Params": "{'DT__alpha': 0 'DT__class_weight': 'balanced' 'DT__criterion': 'gini'}nannan",
          "Dataset": "madelon",
          "Hyperparameters": "{'DT__alpha': 0",
          "Score": 0.81025641,
          "Unnamed: 4": " 'DT__class_weight': 'balanced'",
          "Unnamed: 5": " 'DT__criterion': 'gini'}",
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "DT",
          "Best_Params": "{'DT__alpha': 0.01 'DT__class_weight': 'balanced' 'DT__criterion': 'gini'}nannan",
          "Dataset": "abalone",
          "Hyperparameters": "{'DT__alpha': 0.01",
          "Score": 0.618223327,
          "Unnamed: 4": " 'DT__class_weight': 'balanced'",
          "Unnamed: 5": " 'DT__criterion': 'gini'}",
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "KNN",
          "Best_Params": "{'KNN__metric': 'manhattan' 'KNN__n_neighbors': 10 'KNN__weights': 'distance'}nannan",
          "Dataset": "madelon",
          "Hyperparameters": "{'KNN__metric': 'manhattan'",
          "Score": 0.8641025640000001,
          "Unnamed: 4": " 'KNN__n_neighbors': 10",
          "Unnamed: 5": " 'KNN__weights': 'distance'}",
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "KNN",
          "Best_Params": "{'KNN__metric': 'chebyshev' 'KNN__n_neighbors': 34 'KNN__weights': 'distance'}nannan",
          "Dataset": "abalone",
          "Hyperparameters": "{'KNN__metric': 'chebyshev'",
          "Score": 0.628263418,
          "Unnamed: 4": " 'KNN__n_neighbors': 34",
          "Unnamed: 5": " 'KNN__weights': 'distance'}",
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "SVM_Lin",
          "Best_Params": "{'SVM__alpha': 0.1 'SVM__n_iter': 687}nannannan",
          "Dataset": "madelon",
          "Hyperparameters": "{'SVM__alpha': 0.1",
          "Score": 0.601282051,
          "Unnamed: 4": " 'SVM__n_iter': 687}",
          "Unnamed: 5": null,
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "SVM_Lin",
          "Best_Params": "{'SVM__alpha': 0.0001 'SVM__n_iter': 428}nannannan",
          "Dataset": "abalone",
          "Hyperparameters": "{'SVM__alpha': 0.0001",
          "Score": 0.6220481760000001,
          "Unnamed: 4": " 'SVM__n_iter': 428}",
          "Unnamed: 5": null,
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "SVM_RBF",
          "Best_Params": "{'SVM__alpha': 0.00031622776601683794 'SVM__gamma_frac': 0.15000000000000002 'SVM__n_iter': 687}nannan",
          "Dataset": "madelon",
          "Hyperparameters": "{'SVM__alpha': 0.00031622776601683794",
          "Score": 0.837179487,
          "Unnamed: 4": " 'SVM__gamma_frac': 0.15000000000000002",
          "Unnamed: 5": " 'SVM__n_iter': 687}",
          "Unnamed: 6": null,
          "Unnamed: 7": null
         },
         {
          "Algorithm": "SVM_RBF",
          "Best_Params": "{'SVM__alpha': 0.0031622776601683794 'SVM__gamma_frac': 0.2 'SVM__n_iter': 428}nannan",
          "Dataset": "abalone",
          "Hyperparameters": "{'SVM__alpha': 0.0031622776601683794",
          "Score": 0.6338597570000001,
          "Unnamed: 4": " 'SVM__gamma_frac': 0.2",
          "Unnamed: 5": " 'SVM__n_iter': 428}",
          "Unnamed: 6": null,
          "Unnamed: 7": null
         }
        ]
       },
       "encoding": {
        "color": {
         "field": "Dataset",
         "type": "nominal"
        },
        "column": {
         "field": "Dataset",
         "type": "nominal"
        },
        "x": {
         "field": "Algorithm",
         "type": "nominal"
        },
        "y": {
         "field": "Score",
         "scale": {
          "domain": [
           0,
           1
          ]
         },
         "type": "quantitative"
        }
       },
       "mark": "bar"
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(results).mark_bar().encode(\n",
    "    x='Algorithm:N',\n",
    "    y=alt.Y('Score:Q', scale=alt.Scale(domain=[0.0, 1.0])),\n",
    "    column='Dataset:N',\n",
    "    color='Dataset:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load into DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ANN_abalone_LC_test', 'ANN_abalone_LC_train', 'ANN_abalone_reg', 'ANN_abalone_timing', 'ITERtestSET_ANN_abalone', 'ITERtestSET_ANN_OF_abalone', 'ITER_base_ANN_abalone', 'ITER_base_ANN_OF_abalone'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = {}\n",
    "for fname in relevant_files:\n",
    "    key = fname.split('.')[0]\n",
    "    df_dict[key] = pd.read_csv(RESULTS_PATH / fname)\n",
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>3.541534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>3.452417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>2.824890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>1.716508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>1.597426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>1.638496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.024314</td>\n",
       "      <td>1.730237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>1.188533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>0.797789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      test     train\n",
       "0         0.1  0.000703  3.541534\n",
       "1         0.2  0.001253  3.452417\n",
       "2         0.3  0.001380  2.824890\n",
       "3         0.4  0.001919  1.716508\n",
       "4         0.5  0.002644  1.597426\n",
       "5         0.6  0.005458  1.638496\n",
       "6         0.7  0.024314  1.730237\n",
       "7         0.8  0.003949  1.188533\n",
       "8         0.9  0.009882  0.797789"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['ANN_abalone_timing']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate Into Learning Curves, Timing Curves, OF curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_learning_df =  df_dict['ANN_abalone_LC_test']\n",
    "# CV_cols = ['CV_1', 'CV_2', 'CV_3', 'CV_4', 'CV_5']\n",
    "# test_learning_df.columns = ['Iterations'] + CV_cols\n",
    "# test_learning_df['CV_Mean'] = test_learning_df[CV_cols].mean(axis=1)\n",
    "# test_learning_df['Split'] = 'Test'\n",
    "# test_learning_df[['Iterations', 'Split', 'CV_Mean']]\n",
    "\n",
    "def tidy_learning_curve(base_df, split=None, dataset=None, algorithm=None):\n",
    "    \"\"\"Convert a learning curve df into tidy format depending\n",
    "    on train/test split specified\"\"\"\n",
    "    assert split.upper() in ['TRAIN', 'TEST'], \\\n",
    "    'Split must be \"Train\" or \"Test\"'\n",
    "    CV_cols = ['CV_1', 'CV_2', 'CV_3', 'CV_4', 'CV_5']\n",
    "    tidy_df = base_df.copy()\n",
    "    tidy_df.columns = ['Iterations'] + CV_cols\n",
    "    tidy_df['CV_Mean'] = tidy_df[CV_cols].mean(axis=1)\n",
    "    tidy_df['Split'] = split\n",
    "    tidy_df[['Iterations', 'Split', 'CV_Mean']]\n",
    "    \n",
    "    # Optionally add algorithm and dataset\n",
    "    if algorithm:\n",
    "        tidy_df['Algorithm'] = algorithm\n",
    "    if dataset:\n",
    "        tidy_df['Dataset'] = dataset    \n",
    "    return tidy_df\n",
    "\n",
    "def get_learning_curve_dfs(df_dict, algorithm=None, dataset=None):\n",
    "    \"\"\"Given a dictionary with keys of fnames and values\n",
    "    of dataframes, search for learning curve dfs, tidy them \n",
    "    and return them as a single dataframe\"\"\"\n",
    "    learning_curve_dfs = []\n",
    "    # Search in df_dict for LC which indicates\n",
    "    # Learning curve df\n",
    "    for key, df in df_dict.items():\n",
    "        if 'LC' in key.split('_'):\n",
    "            #print(key)\n",
    "            split = key.split(\"_\")[-1]\n",
    "            #print(f'Split: {split}')\n",
    "            #display(df.head())\n",
    "            # Tidy data and append to list\n",
    "            learning_curve_dfs.append(tidy_learning_curve(df, split=split,\n",
    "                                                         algorithm=algorithm,\n",
    "                                                         dataset=dataset))\n",
    "    # Concat together\n",
    "    #[display(df) for df in learning_curve_dfs]\n",
    "    learning_curve_df = pd.concat(learning_curve_dfs)\n",
    "    return learning_curve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test     9\n",
       "train    9\n",
       "Name: Split, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_learning_curve_dfs(df_dict).Split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-f31ef578f64c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlearning_curve_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m'LC'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;31m#print(key)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_dict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "learning_curve_dfs = []\n",
    "for key, df in df_dict.items():\n",
    "    if 'LC' in key.split('_'):\n",
    "        #print(key)\n",
    "        #display(df.head())\n",
    "        learning_curve_dfs.append(tidy_learning_curve(df, split=key.split('_')[-1]))\n",
    "learning_curve_df = pd.concat(learning_curve_dfs)\n",
    "learning_curve_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "background": "white",
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-0ef653253927c2c2996df92c9e022fd4"
       },
       "datasets": {
        "data-0ef653253927c2c2996df92c9e022fd4": [
         {
          "CV_1": 0.3169041439341773,
          "CV_2": 0.32336573026228194,
          "CV_3": 0.3231112300419231,
          "CV_4": 0.3274730175720274,
          "CV_5": 0.3292748193738293,
          "CV_Mean": 0.3240257882368478,
          "Iterations": 50,
          "Split": "test"
         },
         {
          "CV_1": 0.3169041439341773,
          "CV_2": 0.3159987573780677,
          "CV_3": 0.3264115600749264,
          "CV_4": 0.3291231825885291,
          "CV_5": 0.3165105699759165,
          "CV_Mean": 0.3209896427903234,
          "Iterations": 100,
          "Split": "test"
         },
         {
          "CV_1": 0.3145117149566538,
          "CV_2": 0.33374297505226963,
          "CV_3": 0.3496871953624228,
          "CV_4": 0.3553280022747781,
          "CV_5": 0.34781752149697065,
          "CV_Mean": 0.34021748182861894,
          "Iterations": 292,
          "Split": "test"
         },
         {
          "CV_1": 0.5801338903403804,
          "CV_2": 0.5223824459602511,
          "CV_3": 0.5633195189459953,
          "CV_4": 0.5961769781039018,
          "CV_5": 0.5644209118401208,
          "CV_Mean": 0.5652867490381299,
          "Iterations": 584,
          "Split": "test"
         },
         {
          "CV_1": 0.5798660881494035,
          "CV_2": 0.5465399985266954,
          "CV_3": 0.5584306928429158,
          "CV_4": 0.5691197052206248,
          "CV_5": 0.5528216712465593,
          "CV_Mean": 0.5613556311972399,
          "Iterations": 876,
          "Split": "test"
         },
         {
          "CV_1": 0.5753313760829163,
          "CV_2": 0.5551140898594076,
          "CV_3": 0.5684895228444506,
          "CV_4": 0.5994951477587049,
          "CV_5": 0.5669149724685735,
          "CV_Mean": 0.5730690218028106,
          "Iterations": 1169,
          "Split": "test"
         },
         {
          "CV_1": 0.5726976741809918,
          "CV_2": 0.5533122880576057,
          "CV_3": 0.5539234716447362,
          "CV_4": 0.5981463093490031,
          "CV_5": 0.5843663787424153,
          "CV_Mean": 0.5724892243949504,
          "Iterations": 1461,
          "Split": "test"
         },
         {
          "CV_1": 0.5887176317180327,
          "CV_2": 0.5587523408983238,
          "CV_3": 0.557046175189614,
          "CV_4": 0.5964383693136772,
          "CV_5": 0.5954024940153503,
          "CV_Mean": 0.5792714022269996,
          "Iterations": 1753,
          "Split": "test"
         },
         {
          "CV_1": 0.6181418596962095,
          "CV_2": 0.576814738271066,
          "CV_3": 0.5892090663312456,
          "CV_4": 0.5780011201833587,
          "CV_5": 0.5558427704479872,
          "CV_Mean": 0.5836019109859735,
          "Iterations": 2046,
          "Split": "test"
         },
         {
          "CV_1": 0.3076923076923077,
          "CV_2": 0.30303030303030304,
          "CV_3": 0.30303030303030304,
          "CV_4": 0.30303030303030304,
          "CV_5": 0.30303030303030304,
          "CV_Mean": 0.3039627039627039,
          "Iterations": 50,
          "Split": "train"
         },
         {
          "CV_1": 0.3142857142857143,
          "CV_2": 0.3103448275862069,
          "CV_3": 0.3103448275862069,
          "CV_4": 0.3103448275862069,
          "CV_5": 0.3103448275862069,
          "CV_Mean": 0.31113300492610835,
          "Iterations": 100,
          "Split": "train"
         },
         {
          "CV_1": 0.3222563427652263,
          "CV_2": 0.3425,
          "CV_3": 0.3425,
          "CV_4": 0.3425,
          "CV_5": 0.3425,
          "CV_Mean": 0.3384512685530453,
          "Iterations": 292,
          "Split": "train"
         },
         {
          "CV_1": 0.5870143434106174,
          "CV_2": 0.5315543346528098,
          "CV_3": 0.5833618107315149,
          "CV_4": 0.5833618107315149,
          "CV_5": 0.5833618107315149,
          "CV_Mean": 0.5737308220515944,
          "Iterations": 584,
          "Split": "train"
         },
         {
          "CV_1": 0.5909798205226157,
          "CV_2": 0.5703968206097406,
          "CV_3": 0.5645755041453968,
          "CV_4": 0.5645755041453968,
          "CV_5": 0.5645755041453968,
          "CV_Mean": 0.5710206307137093,
          "Iterations": 876,
          "Split": "train"
         },
         {
          "CV_1": 0.5584192408386022,
          "CV_2": 0.5630427612107077,
          "CV_3": 0.5735182528747218,
          "CV_4": 0.5823256452607695,
          "CV_5": 0.5823256452607695,
          "CV_Mean": 0.5719263090891141,
          "Iterations": 1169,
          "Split": "train"
         },
         {
          "CV_1": 0.5629081549085619,
          "CV_2": 0.5641779884205228,
          "CV_3": 0.5755341089255726,
          "CV_4": 0.582057102368536,
          "CV_5": 0.582057102368536,
          "CV_Mean": 0.5733468913983459,
          "Iterations": 1461,
          "Split": "train"
         },
         {
          "CV_1": 0.5912142230091724,
          "CV_2": 0.570351854547335,
          "CV_3": 0.573204434776521,
          "CV_4": 0.5648996156644428,
          "CV_5": 0.6112813557398679,
          "CV_Mean": 0.5821902967474678,
          "Iterations": 1753,
          "Split": "train"
         },
         {
          "CV_1": 0.6133979374110954,
          "CV_2": 0.5771482110535673,
          "CV_3": 0.5934623065339873,
          "CV_4": 0.5622278334049963,
          "CV_5": 0.5659455201487509,
          "CV_Mean": 0.5824363617104794,
          "Iterations": 2046,
          "Split": "train"
         }
        ]
       },
       "encoding": {
        "color": {
         "field": "Split",
         "type": "nominal"
        },
        "x": {
         "field": "Iterations",
         "type": "quantitative"
        },
        "y": {
         "field": "CV_Mean",
         "scale": {
          "domain": [
           0,
           1
          ]
         },
         "type": "quantitative"
        }
       },
       "mark": "line"
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(get_learning_curve_dfs(df_dict)).mark_line().encode(\n",
    "    x='Iterations:Q',\n",
    "    y=alt.Y('CV_Mean:Q', scale=alt.Scale(domain=[0.0, 1.0])),\n",
    "    color='Split:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_timing_curve(timing_df, algorithm=None, dataset=None):\n",
    "    \"\"\"Convert a learning curve df into tidy format\"\"\"\n",
    "\n",
    "    tidy_timing_df = timing_df.copy()\n",
    "    tidy_timing_df.columns = ['Training_Fractional_Size', 'Test', 'Train']\n",
    "    # Originally the first column is the test size\n",
    "    # So setting the training size is just 1 - this\n",
    "    tidy_timing_df['Training_Fractional_Size'] = (1 - tidy_timing_df['Training_Fractional_Size']).round(2)\n",
    "    tidy_timing_df = tidy_timing_df.melt(id_vars='Training_Fractional_Size', var_name='Function', value_name='Time')\n",
    "    tidy_timing_df['Function'] = tidy_timing_df['Function'].map({'Test':'Predict', 'Train':'Fit'})\n",
    "    \n",
    "    # Optionally add algorithm and dataset\n",
    "    if algorithm:\n",
    "        tidy_timing_df['Algorithm'] = algorithm\n",
    "    if dataset:\n",
    "        tidy_timing_df['Dataset'] = dataset\n",
    "    return tidy_timing_df\n",
    "    \n",
    "def get_timing_curve(df_dict, algorithm=None, dataset=None):\n",
    "    timing_curves = []\n",
    "    for key, df in df_dict.items():\n",
    "        if 'timing' in key.split('_'):\n",
    "            timing_df = df.copy()\n",
    "            timing_df = tidy_timing_curve(timing_df, algorithm=algorithm, dataset=dataset)\n",
    "            timing_curves.append(timing_df)\n",
    "    timing_curve_df = pd.concat(timing_curves)\n",
    "    return timing_curve_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>test</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>3.541534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>3.452417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>2.824890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>1.716508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>1.597426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>1.638496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.024314</td>\n",
       "      <td>1.730237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>1.188533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>0.797789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      test     train\n",
       "0         0.1  0.000703  3.541534\n",
       "1         0.2  0.001253  3.452417\n",
       "2         0.3  0.001380  2.824890\n",
       "3         0.4  0.001919  1.716508\n",
       "4         0.5  0.002644  1.597426\n",
       "5         0.6  0.005458  1.638496\n",
       "6         0.7  0.024314  1.730237\n",
       "7         0.8  0.003949  1.188533\n",
       "8         0.9  0.009882  0.797789"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['ANN_abalone_timing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training_Fractional_Size</th>\n",
       "      <th>Function</th>\n",
       "      <th>Time</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.4</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.024314</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.003949</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1</td>\n",
       "      <td>Predict</td>\n",
       "      <td>0.009882</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>Fit</td>\n",
       "      <td>3.541534</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8</td>\n",
       "      <td>Fit</td>\n",
       "      <td>3.452417</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.7</td>\n",
       "      <td>Fit</td>\n",
       "      <td>2.824890</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.6</td>\n",
       "      <td>Fit</td>\n",
       "      <td>1.716508</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5</td>\n",
       "      <td>Fit</td>\n",
       "      <td>1.597426</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4</td>\n",
       "      <td>Fit</td>\n",
       "      <td>1.638496</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.3</td>\n",
       "      <td>Fit</td>\n",
       "      <td>1.730237</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.2</td>\n",
       "      <td>Fit</td>\n",
       "      <td>1.188533</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1</td>\n",
       "      <td>Fit</td>\n",
       "      <td>0.797789</td>\n",
       "      <td>ANN</td>\n",
       "      <td>abalone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Training_Fractional_Size Function      Time Algorithm  Dataset\n",
       "0                        0.9  Predict  0.000703       ANN  abalone\n",
       "1                        0.8  Predict  0.001253       ANN  abalone\n",
       "2                        0.7  Predict  0.001380       ANN  abalone\n",
       "3                        0.6  Predict  0.001919       ANN  abalone\n",
       "4                        0.5  Predict  0.002644       ANN  abalone\n",
       "5                        0.4  Predict  0.005458       ANN  abalone\n",
       "6                        0.3  Predict  0.024314       ANN  abalone\n",
       "7                        0.2  Predict  0.003949       ANN  abalone\n",
       "8                        0.1  Predict  0.009882       ANN  abalone\n",
       "9                        0.9      Fit  3.541534       ANN  abalone\n",
       "10                       0.8      Fit  3.452417       ANN  abalone\n",
       "11                       0.7      Fit  2.824890       ANN  abalone\n",
       "12                       0.6      Fit  1.716508       ANN  abalone\n",
       "13                       0.5      Fit  1.597426       ANN  abalone\n",
       "14                       0.4      Fit  1.638496       ANN  abalone\n",
       "15                       0.3      Fit  1.730237       ANN  abalone\n",
       "16                       0.2      Fit  1.188533       ANN  abalone\n",
       "17                       0.1      Fit  0.797789       ANN  abalone"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_timing_curve(df_dict, dataset='abalone', algorithm='ANN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Timing Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.vegalite.v2+json": {
       "$schema": "https://vega.github.io/schema/vega-lite/v2.6.0.json",
       "config": {
        "background": "white",
        "view": {
         "height": 300,
         "width": 400
        }
       },
       "data": {
        "name": "data-d89bb5eefc241f333e7c77aed5850789"
       },
       "datasets": {
        "data-d89bb5eefc241f333e7c77aed5850789": [
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.0007031999998616811,
          "Training_Fractional_Size": 0.9
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.0012526999998954125,
          "Training_Fractional_Size": 0.8
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.0013798999998471118,
          "Training_Fractional_Size": 0.7
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.001918999999816151,
          "Training_Fractional_Size": 0.6
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.002643600000283186,
          "Training_Fractional_Size": 0.5
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.005457700000079058,
          "Training_Fractional_Size": 0.4
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.024314000000231317,
          "Training_Fractional_Size": 0.3
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.0039494000002378024,
          "Training_Fractional_Size": 0.2
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Predict",
          "Time": 0.009881899999982123,
          "Training_Fractional_Size": 0.1
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 3.5415342999999666,
          "Training_Fractional_Size": 0.9
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 3.4524166999999584,
          "Training_Fractional_Size": 0.8
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 2.824890300000334,
          "Training_Fractional_Size": 0.7
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 1.7165076000001136,
          "Training_Fractional_Size": 0.6
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 1.597425699999803,
          "Training_Fractional_Size": 0.5
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 1.6384963000000423,
          "Training_Fractional_Size": 0.4
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 1.7302372999997715,
          "Training_Fractional_Size": 0.3
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 1.1885333999998693,
          "Training_Fractional_Size": 0.2
         },
         {
          "Algorithm": "ANN",
          "Dataset": "abalone",
          "Function": "Fit",
          "Time": 0.7977885000000242,
          "Training_Fractional_Size": 0.1
         }
        ]
       },
       "encoding": {
        "color": {
         "field": "Function",
         "type": "nominal"
        },
        "x": {
         "field": "Training_Fractional_Size",
         "type": "quantitative"
        },
        "y": {
         "field": "Time",
         "type": "quantitative"
        }
       },
       "mark": "line"
      },
      "image/png": "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",
      "text/plain": [
       "<VegaLite 2 object>\n",
       "\n",
       "If you see this message, it means the renderer has not been properly enabled\n",
       "for the frontend that you are using. For more information, see\n",
       "https://altair-viz.github.io/user_guide/troubleshooting.html\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(get_timing_curve(df_dict, dataset='abalone', algorithm='ANN')).mark_line().encode(\n",
    "    x='Training_Fractional_Size:Q',\n",
    "    y='Time:Q',\n",
    "    color='Function:N'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each inddividual algorithm is going to have different hyper parameters\n",
    "\n",
    "To come up with meaningful plots, may have to do facet plots across \n",
    "the alpha values and other \n",
    "\n",
    "Columns/Colors can be nominal\n",
    "\n",
    "Y should be cross val score or time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_MLP__activation</th>\n",
       "      <th>param_MLP__alpha</th>\n",
       "      <th>param_MLP__hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.225997</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0.581741</td>\n",
       "      <td>0.586657</td>\n",
       "      <td>relu</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>{'MLP__activation': 'relu', 'MLP__alpha': 10.0...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.551251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584358</td>\n",
       "      <td>0.591831</td>\n",
       "      <td>0.588927</td>\n",
       "      <td>0.582695</td>\n",
       "      <td>0.580703</td>\n",
       "      <td>0.589934</td>\n",
       "      <td>0.057442</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.017127</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.531294</td>\n",
       "      <td>0.532930</td>\n",
       "      <td>relu</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>{'MLP__activation': 'relu', 'MLP__alpha': 10.0...</td>\n",
       "      <td>136</td>\n",
       "      <td>0.522201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520757</td>\n",
       "      <td>0.543399</td>\n",
       "      <td>0.554373</td>\n",
       "      <td>0.530121</td>\n",
       "      <td>0.531280</td>\n",
       "      <td>0.535905</td>\n",
       "      <td>0.086310</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.012144</td>\n",
       "      <td>0.010654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125401</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.541019</td>\n",
       "      <td>0.543287</td>\n",
       "      <td>relu</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(20,)</td>\n",
       "      <td>{'MLP__activation': 'relu', 'MLP__alpha': 10.0...</td>\n",
       "      <td>103</td>\n",
       "      <td>0.544865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522013</td>\n",
       "      <td>0.533139</td>\n",
       "      <td>0.534003</td>\n",
       "      <td>0.530742</td>\n",
       "      <td>0.528284</td>\n",
       "      <td>0.535424</td>\n",
       "      <td>0.034865</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.018981</td>\n",
       "      <td>0.013186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.184801</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.542441</td>\n",
       "      <td>0.546791</td>\n",
       "      <td>relu</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(10, 10)</td>\n",
       "      <td>{'MLP__activation': 'relu', 'MLP__alpha': 10.0...</td>\n",
       "      <td>96</td>\n",
       "      <td>0.556592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519567</td>\n",
       "      <td>0.555113</td>\n",
       "      <td>0.564541</td>\n",
       "      <td>0.542333</td>\n",
       "      <td>0.543005</td>\n",
       "      <td>0.551032</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>0.008002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.505071</td>\n",
       "      <td>0.510227</td>\n",
       "      <td>relu</td>\n",
       "      <td>10.0</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>{'MLP__activation': 'relu', 'MLP__alpha': 10.0...</td>\n",
       "      <td>162</td>\n",
       "      <td>0.361345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539315</td>\n",
       "      <td>0.551384</td>\n",
       "      <td>0.548433</td>\n",
       "      <td>0.545998</td>\n",
       "      <td>0.522466</td>\n",
       "      <td>0.550251</td>\n",
       "      <td>0.055953</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.072766</td>\n",
       "      <td>0.072363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       0.225997         0.001601         0.581741          0.586657   \n",
       "1       0.256000         0.001402         0.531294          0.532930   \n",
       "2       0.125401         0.001999         0.541019          0.543287   \n",
       "3       0.184801         0.002599         0.542441          0.546791   \n",
       "4       0.171400         0.001600         0.505071          0.510227   \n",
       "\n",
       "  param_MLP__activation  param_MLP__alpha param_MLP__hidden_layer_sizes  \\\n",
       "0                  relu              10.0                         (10,)   \n",
       "1                  relu              10.0                          (5,)   \n",
       "2                  relu              10.0                         (20,)   \n",
       "3                  relu              10.0                      (10, 10)   \n",
       "4                  relu              10.0                        (5, 5)   \n",
       "\n",
       "                                              params  rank_test_score  \\\n",
       "0  {'MLP__activation': 'relu', 'MLP__alpha': 10.0...               40   \n",
       "1  {'MLP__activation': 'relu', 'MLP__alpha': 10.0...              136   \n",
       "2  {'MLP__activation': 'relu', 'MLP__alpha': 10.0...              103   \n",
       "3  {'MLP__activation': 'relu', 'MLP__alpha': 10.0...               96   \n",
       "4  {'MLP__activation': 'relu', 'MLP__alpha': 10.0...              162   \n",
       "\n",
       "   split0_test_score       ...         split2_test_score  split2_train_score  \\\n",
       "0           0.551251       ...                  0.584358            0.591831   \n",
       "1           0.522201       ...                  0.520757            0.543399   \n",
       "2           0.544865       ...                  0.522013            0.533139   \n",
       "3           0.556592       ...                  0.519567            0.555113   \n",
       "4           0.361345       ...                  0.539315            0.551384   \n",
       "\n",
       "   split3_test_score  split3_train_score  split4_test_score  \\\n",
       "0           0.588927            0.582695           0.580703   \n",
       "1           0.554373            0.530121           0.531280   \n",
       "2           0.534003            0.530742           0.528284   \n",
       "3           0.564541            0.542333           0.543005   \n",
       "4           0.548433            0.545998           0.522466   \n",
       "\n",
       "   split4_train_score  std_fit_time  std_score_time  std_test_score  \\\n",
       "0            0.589934      0.057442        0.000801        0.017127   \n",
       "1            0.535905      0.086310        0.000488        0.012144   \n",
       "2            0.535424      0.034865        0.001097        0.018981   \n",
       "3            0.551032      0.035226        0.002724        0.016773   \n",
       "4            0.550251      0.055953        0.000800        0.072766   \n",
       "\n",
       "   std_train_score  \n",
       "0         0.007014  \n",
       "1         0.010654  \n",
       "2         0.013186  \n",
       "3         0.008002  \n",
       "4         0.072363  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['ANN_abalone_reg'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ANN_abalone_LC_test', 'ANN_abalone_LC_train', 'ANN_abalone_reg', 'ANN_abalone_timing', 'ITERtestSET_ANN_abalone', 'ITERtestSET_ANN_OF_abalone', 'ITER_base_ANN_abalone', 'ITER_base_ANN_OF_abalone'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITER_base_ANN_OF_abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Could do column for time vs score or something\n",
    "Column could also be overfitting or not\n",
    "\n",
    "X is iterations\n",
    "Y is score or time\n",
    "\n",
    "Color is Train/Test\n",
    "\n",
    "Scatterplot iteration by time, score is gradient of color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "testing_non_OF = df_dict['ITERtestSET_ANN_abalone']\n",
    "testing_OF = df_dict['ITERtestSET_ANN_OF_abalone']\n",
    "testing_non_OF.iloc[:, 0].name\n",
    "\n",
    "def get_overfitting_curve(df_dict, algorithm=None, dataset=None):\n",
    "    iter_dfs = []\n",
    "    for key, df in df_dict.items():\n",
    "        if 'ITERtestSET' in key.split('_'):\n",
    "            if 'OF' in key.split('_'):\n",
    "                of_iter_df = df.copy()\n",
    "                of_iter_df = tidy_iter_df(of_iter_df, param_set='No_Regularization', \n",
    "                                          algorithm=algorithm, dataset=dataset)\n",
    "                iter_dfs.append(of_iter_df)\n",
    "            else:\n",
    "                non_of_iter_df = df.copy()\n",
    "                non_of_iter_df = tidy_iter_df(non_of_iter_df, param_set='Best_Hyperparameters', \n",
    "                                          algorithm=algorithm, dataset=dataset)\n",
    "                iter_dfs.append(non_of_iter_df)                \n",
    "    #iter_dfs =pd.concat(iter_dfs)\n",
    "    return iter_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_iter_df(iter_df, param_set=None, dataset=None, algorithm=None):\n",
    "    # Melt data\n",
    "    # Find max iteration columns\n",
    "    iteration_column = iter_df.filter(regex='(_max_iter$|_estimators$|_iter$)').columns.values.tolist()[0]\n",
    "    \n",
    "    tidied_iter_df = (pd.melt(iter_df, id_vars=iteration_column, var_name='Split', value_name='Score')\n",
    "                     .rename(columns={iteration_column:'Max_Iterations/Estimators'}))\n",
    "    # Clean up split\n",
    "    tidied_iter_df.Split = tidied_iter_df.Split.str.split(' ').str.get(0).str.title()\n",
    "    # Add apram_set (e.g. overfitting or not), dataset, algorithm if applicacable\n",
    "    tidied_iter_df['Hyperparameters'] = param_set    \n",
    "    if algorithm:\n",
    "        tidied_iter_df['Algorithm'] = algorithm\n",
    "    if dataset:\n",
    "        tidied_iter_df['Dataset'] = dataset\n",
    "    return tidied_iter_df\n",
    "\n",
    "\n",
    "\n",
    "# overfitting_analysis_df = pd.concat([tidy_iter_df(testing_OF, param_set='No_Regularization', dataset='Abalone', algorithm='NN'),\n",
    "#            tidy_iter_df(testing_non_OF, param_set='Best_Hyperparameters', dataset='Abalone', algorithm='NN'),\n",
    "#           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max_Iterations/Estimators</th>\n",
       "      <th>Split</th>\n",
       "      <th>Score</th>\n",
       "      <th>Hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.482236</td>\n",
       "      <td>Best_Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.553529</td>\n",
       "      <td>Best_Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.578643</td>\n",
       "      <td>Best_Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.611336</td>\n",
       "      <td>Best_Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.633146</td>\n",
       "      <td>Best_Hyperparameters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Max_Iterations/Estimators Split     Score       Hyperparameters\n",
       "0                          1  Test  0.482236  Best_Hyperparameters\n",
       "1                          2  Test  0.553529  Best_Hyperparameters\n",
       "2                          4  Test  0.578643  Best_Hyperparameters\n",
       "3                          8  Test  0.611336  Best_Hyperparameters\n",
       "4                         16  Test  0.633146  Best_Hyperparameters"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = get_overfitting_curve(df_dict)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Overfitting curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afurrier\\AppData\\Local\\Continuum\\miniconda3\\envs\\ml\\lib\\site-packages\\altair\\vegalite\\v2\\api.py:97: UserWarning: data of type <class 'list'> not recognized\n",
      "  warnings.warn(\"data of type {0} not recognized\".format(type(data)))\n"
     ]
    },
    {
     "ename": "SchemaValidationError",
     "evalue": "Invalid specification\n\n        altair.vegalite.v2.api.Chart->data, validating 'anyOf'\n\n        [    Max_Iterations/Estimators  Split     Score       Hyperparameters  \\\n0                           1   Test  0.482236  Best_Hyperparameters   \n1                           2   Test  0.553529  Best_Hyperparameters   \n2                           4   Test  0.578643  Best_Hyperparameters   \n3                           8   Test  0.611336  Best_Hyperparameters   \n4                          16   Test  0.633146  Best_Hyperparameters   \n5                          32   Test  0.649362  Best_Hyperparameters   \n6                          64   Test  0.652622  Best_Hyperparameters   \n7                         128   Test  0.647394  Best_Hyperparameters   \n8                         256   Test  0.647394  Best_Hyperparameters   \n9                         512   Test  0.647394  Best_Hyperparameters   \n10                       1024   Test  0.647394  Best_Hyperparameters   \n11                       2048   Test  0.647394  Best_Hyperparameters   \n12                       2100   Test  0.647394  Best_Hyperparameters   \n13                       2200   Test  0.647394  Best_Hyperparameters   \n14                       2300   Test  0.647394  Best_Hyperparameters   \n15                       2400   Test  0.647394  Best_Hyperparameters   \n16                       2500   Test  0.647394  Best_Hyperparameters   \n17                       2600   Test  0.647394  Best_Hyperparameters   \n18                       2700   Test  0.647394  Best_Hyperparameters   \n19                       2800   Test  0.647394  Best_Hyperparameters   \n20                       2900   Test  0.647394  Best_Hyperparameters   \n21                       3000   Test  0.647394  Best_Hyperparameters   \n22                          1  Train  0.484674  Best_Hyperparameters   \n23                          2  Train  0.565532  Best_Hyperparameters   \n24                          4  Train  0.588953  Best_Hyperparameters   \n25                          8  Train  0.614279  Best_Hyperparameters   \n26                         16  Train  0.653179  Best_Hyperparameters   \n27                         32  Train  0.663983  Best_Hyperparameters   \n28                         64  Train  0.668061  Best_Hyperparameters   \n29                        128  Train  0.663552  Best_Hyperparameters   \n30                        256  Train  0.663552  Best_Hyperparameters   \n31                        512  Train  0.663552  Best_Hyperparameters   \n32                       1024  Train  0.663552  Best_Hyperparameters   \n33                       2048  Train  0.663552  Best_Hyperparameters   \n34                       2100  Train  0.663552  Best_Hyperparameters   \n35                       2200  Train  0.663552  Best_Hyperparameters   \n36                       2300  Train  0.663552  Best_Hyperparameters   \n37                       2400  Train  0.663552  Best_Hyperparameters   \n38                       2500  Train  0.663552  Best_Hyperparameters   \n39                       2600  Train  0.663552  Best_Hyperparameters   \n40                       2700  Train  0.663552  Best_Hyperparameters   \n41                       2800  Train  0.663552  Best_Hyperparameters   \n42                       2900  Train  0.663552  Best_Hyperparameters   \n43                       3000  Train  0.663552  Best_Hyperparameters   \n\n   Algorithm  Dataset  \n0        ANN  abalone  \n1        ANN  abalone  \n2        ANN  abalone  \n3        ANN  abalone  \n4        ANN  abalone  \n5        ANN  abalone  \n6        ANN  abalone  \n7        ANN  abalone  \n8        ANN  abalone  \n9        ANN  abalone  \n10       ANN  abalone  \n11       ANN  abalone  \n12       ANN  abalone  \n13       ANN  abalone  \n14       ANN  abalone  \n15       ANN  abalone  \n16       ANN  abalone  \n17       ANN  abalone  \n18       ANN  abalone  \n19       ANN  abalone  \n20       ANN  abalone  \n21       ANN  abalone  \n22       ANN  abalone  \n23       ANN  abalone  \n24       ANN  abalone  \n25       ANN  abalone  \n26       ANN  abalone  \n27       ANN  abalone  \n28       ANN  abalone  \n29       ANN  abalone  \n30       ANN  abalone  \n31       ANN  abalone  \n32       ANN  abalone  \n33       ANN  abalone  \n34       ANN  abalone  \n35       ANN  abalone  \n36       ANN  abalone  \n37       ANN  abalone  \n38       ANN  abalone  \n39       ANN  abalone  \n40       ANN  abalone  \n41       ANN  abalone  \n42       ANN  abalone  \n43       ANN  abalone  ,     Max_Iterations/Estimators  Split     Score    Hyperparameters Algorithm  \\\n0                           1   Test  0.485325  No_Regularization       ANN   \n1                           2   Test  0.558503  No_Regularization       ANN   \n2                           4   Test  0.583605  No_Regularization       ANN   \n3                           8   Test  0.607264  No_Regularization       ANN   \n4                          16   Test  0.638533  No_Regularization       ANN   \n5                          32   Test  0.646394  No_Regularization       ANN   \n6                          64   Test  0.645906  No_Regularization       ANN   \n7                         128   Test  0.645906  No_Regularization       ANN   \n8                         256   Test  0.645906  No_Regularization       ANN   \n9                         512   Test  0.645906  No_Regularization       ANN   \n10                       1024   Test  0.645906  No_Regularization       ANN   \n11                       2048   Test  0.645906  No_Regularization       ANN   \n12                       2100   Test  0.645906  No_Regularization       ANN   \n13                       2200   Test  0.645906  No_Regularization       ANN   \n14                       2300   Test  0.645906  No_Regularization       ANN   \n15                       2400   Test  0.645906  No_Regularization       ANN   \n16                       2500   Test  0.645906  No_Regularization       ANN   \n17                       2600   Test  0.645906  No_Regularization       ANN   \n18                       2700   Test  0.645906  No_Regularization       ANN   \n19                       2800   Test  0.645906  No_Regularization       ANN   \n20                       2900   Test  0.645906  No_Regularization       ANN   \n21                       3000   Test  0.645906  No_Regularization       ANN   \n22                          1  Train  0.486625  No_Regularization       ANN   \n23                          2  Train  0.564506  No_Regularization       ANN   \n24                          4  Train  0.587596  No_Regularization       ANN   \n25                          8  Train  0.613439  No_Regularization       ANN   \n26                         16  Train  0.657852  No_Regularization       ANN   \n27                         32  Train  0.662788  No_Regularization       ANN   \n28                         64  Train  0.662853  No_Regularization       ANN   \n29                        128  Train  0.662853  No_Regularization       ANN   \n30                        256  Train  0.662853  No_Regularization       ANN   \n31                        512  Train  0.662853  No_Regularization       ANN   \n32                       1024  Train  0.662853  No_Regularization       ANN   \n33                       2048  Train  0.662853  No_Regularization       ANN   \n34                       2100  Train  0.662853  No_Regularization       ANN   \n35                       2200  Train  0.662853  No_Regularization       ANN   \n36                       2300  Train  0.662853  No_Regularization       ANN   \n37                       2400  Train  0.662853  No_Regularization       ANN   \n38                       2500  Train  0.662853  No_Regularization       ANN   \n39                       2600  Train  0.662853  No_Regularization       ANN   \n40                       2700  Train  0.662853  No_Regularization       ANN   \n41                       2800  Train  0.662853  No_Regularization       ANN   \n42                       2900  Train  0.662853  No_Regularization       ANN   \n43                       3000  Train  0.662853  No_Regularization       ANN   \n\n    Dataset  \n0   abalone  \n1   abalone  \n2   abalone  \n3   abalone  \n4   abalone  \n5   abalone  \n6   abalone  \n7   abalone  \n8   abalone  \n9   abalone  \n10  abalone  \n11  abalone  \n12  abalone  \n13  abalone  \n14  abalone  \n15  abalone  \n16  abalone  \n17  abalone  \n18  abalone  \n19  abalone  \n20  abalone  \n21  abalone  \n22  abalone  \n23  abalone  \n24  abalone  \n25  abalone  \n26  abalone  \n27  abalone  \n28  abalone  \n29  abalone  \n30  abalone  \n31  abalone  \n32  abalone  \n33  abalone  \n34  abalone  \n35  abalone  \n36  abalone  \n37  abalone  \n38  abalone  \n39  abalone  \n40  abalone  \n41  abalone  \n42  abalone  \n43  abalone  ] is not valid under any of the given schemas\n        ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSchemaValidationError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ml\\lib\\site-packages\\altair\\vegalite\\v2\\api.py\u001b[0m in \u001b[0;36mto_dict\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdct\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'validate'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'deep'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m             \u001b[0mdct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTopLevelMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m         \u001b[1;31m# TODO: following entries are added after validation. Should they be validated?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ml\\lib\\site-packages\\altair\\utils\\schemapi.py\u001b[0m in \u001b[0;36mto_dict\u001b[1;34m(self, validate, ignore, context)\u001b[0m\n\u001b[0;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mjsonschema\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mValidationError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mSchemaValidationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSchemaValidationError\u001b[0m: Invalid specification\n\n        altair.vegalite.v2.api.Chart->data, validating 'anyOf'\n\n        [    Max_Iterations/Estimators  Split     Score       Hyperparameters  \\\n0                           1   Test  0.482236  Best_Hyperparameters   \n1                           2   Test  0.553529  Best_Hyperparameters   \n2                           4   Test  0.578643  Best_Hyperparameters   \n3                           8   Test  0.611336  Best_Hyperparameters   \n4                          16   Test  0.633146  Best_Hyperparameters   \n5                          32   Test  0.649362  Best_Hyperparameters   \n6                          64   Test  0.652622  Best_Hyperparameters   \n7                         128   Test  0.647394  Best_Hyperparameters   \n8                         256   Test  0.647394  Best_Hyperparameters   \n9                         512   Test  0.647394  Best_Hyperparameters   \n10                       1024   Test  0.647394  Best_Hyperparameters   \n11                       2048   Test  0.647394  Best_Hyperparameters   \n12                       2100   Test  0.647394  Best_Hyperparameters   \n13                       2200   Test  0.647394  Best_Hyperparameters   \n14                       2300   Test  0.647394  Best_Hyperparameters   \n15                       2400   Test  0.647394  Best_Hyperparameters   \n16                       2500   Test  0.647394  Best_Hyperparameters   \n17                       2600   Test  0.647394  Best_Hyperparameters   \n18                       2700   Test  0.647394  Best_Hyperparameters   \n19                       2800   Test  0.647394  Best_Hyperparameters   \n20                       2900   Test  0.647394  Best_Hyperparameters   \n21                       3000   Test  0.647394  Best_Hyperparameters   \n22                          1  Train  0.484674  Best_Hyperparameters   \n23                          2  Train  0.565532  Best_Hyperparameters   \n24                          4  Train  0.588953  Best_Hyperparameters   \n25                          8  Train  0.614279  Best_Hyperparameters   \n26                         16  Train  0.653179  Best_Hyperparameters   \n27                         32  Train  0.663983  Best_Hyperparameters   \n28                         64  Train  0.668061  Best_Hyperparameters   \n29                        128  Train  0.663552  Best_Hyperparameters   \n30                        256  Train  0.663552  Best_Hyperparameters   \n31                        512  Train  0.663552  Best_Hyperparameters   \n32                       1024  Train  0.663552  Best_Hyperparameters   \n33                       2048  Train  0.663552  Best_Hyperparameters   \n34                       2100  Train  0.663552  Best_Hyperparameters   \n35                       2200  Train  0.663552  Best_Hyperparameters   \n36                       2300  Train  0.663552  Best_Hyperparameters   \n37                       2400  Train  0.663552  Best_Hyperparameters   \n38                       2500  Train  0.663552  Best_Hyperparameters   \n39                       2600  Train  0.663552  Best_Hyperparameters   \n40                       2700  Train  0.663552  Best_Hyperparameters   \n41                       2800  Train  0.663552  Best_Hyperparameters   \n42                       2900  Train  0.663552  Best_Hyperparameters   \n43                       3000  Train  0.663552  Best_Hyperparameters   \n\n   Algorithm  Dataset  \n0        ANN  abalone  \n1        ANN  abalone  \n2        ANN  abalone  \n3        ANN  abalone  \n4        ANN  abalone  \n5        ANN  abalone  \n6        ANN  abalone  \n7        ANN  abalone  \n8        ANN  abalone  \n9        ANN  abalone  \n10       ANN  abalone  \n11       ANN  abalone  \n12       ANN  abalone  \n13       ANN  abalone  \n14       ANN  abalone  \n15       ANN  abalone  \n16       ANN  abalone  \n17       ANN  abalone  \n18       ANN  abalone  \n19       ANN  abalone  \n20       ANN  abalone  \n21       ANN  abalone  \n22       ANN  abalone  \n23       ANN  abalone  \n24       ANN  abalone  \n25       ANN  abalone  \n26       ANN  abalone  \n27       ANN  abalone  \n28       ANN  abalone  \n29       ANN  abalone  \n30       ANN  abalone  \n31       ANN  abalone  \n32       ANN  abalone  \n33       ANN  abalone  \n34       ANN  abalone  \n35       ANN  abalone  \n36       ANN  abalone  \n37       ANN  abalone  \n38       ANN  abalone  \n39       ANN  abalone  \n40       ANN  abalone  \n41       ANN  abalone  \n42       ANN  abalone  \n43       ANN  abalone  ,     Max_Iterations/Estimators  Split     Score    Hyperparameters Algorithm  \\\n0                           1   Test  0.485325  No_Regularization       ANN   \n1                           2   Test  0.558503  No_Regularization       ANN   \n2                           4   Test  0.583605  No_Regularization       ANN   \n3                           8   Test  0.607264  No_Regularization       ANN   \n4                          16   Test  0.638533  No_Regularization       ANN   \n5                          32   Test  0.646394  No_Regularization       ANN   \n6                          64   Test  0.645906  No_Regularization       ANN   \n7                         128   Test  0.645906  No_Regularization       ANN   \n8                         256   Test  0.645906  No_Regularization       ANN   \n9                         512   Test  0.645906  No_Regularization       ANN   \n10                       1024   Test  0.645906  No_Regularization       ANN   \n11                       2048   Test  0.645906  No_Regularization       ANN   \n12                       2100   Test  0.645906  No_Regularization       ANN   \n13                       2200   Test  0.645906  No_Regularization       ANN   \n14                       2300   Test  0.645906  No_Regularization       ANN   \n15                       2400   Test  0.645906  No_Regularization       ANN   \n16                       2500   Test  0.645906  No_Regularization       ANN   \n17                       2600   Test  0.645906  No_Regularization       ANN   \n18                       2700   Test  0.645906  No_Regularization       ANN   \n19                       2800   Test  0.645906  No_Regularization       ANN   \n20                       2900   Test  0.645906  No_Regularization       ANN   \n21                       3000   Test  0.645906  No_Regularization       ANN   \n22                          1  Train  0.486625  No_Regularization       ANN   \n23                          2  Train  0.564506  No_Regularization       ANN   \n24                          4  Train  0.587596  No_Regularization       ANN   \n25                          8  Train  0.613439  No_Regularization       ANN   \n26                         16  Train  0.657852  No_Regularization       ANN   \n27                         32  Train  0.662788  No_Regularization       ANN   \n28                         64  Train  0.662853  No_Regularization       ANN   \n29                        128  Train  0.662853  No_Regularization       ANN   \n30                        256  Train  0.662853  No_Regularization       ANN   \n31                        512  Train  0.662853  No_Regularization       ANN   \n32                       1024  Train  0.662853  No_Regularization       ANN   \n33                       2048  Train  0.662853  No_Regularization       ANN   \n34                       2100  Train  0.662853  No_Regularization       ANN   \n35                       2200  Train  0.662853  No_Regularization       ANN   \n36                       2300  Train  0.662853  No_Regularization       ANN   \n37                       2400  Train  0.662853  No_Regularization       ANN   \n38                       2500  Train  0.662853  No_Regularization       ANN   \n39                       2600  Train  0.662853  No_Regularization       ANN   \n40                       2700  Train  0.662853  No_Regularization       ANN   \n41                       2800  Train  0.662853  No_Regularization       ANN   \n42                       2900  Train  0.662853  No_Regularization       ANN   \n43                       3000  Train  0.662853  No_Regularization       ANN   \n\n    Dataset  \n0   abalone  \n1   abalone  \n2   abalone  \n3   abalone  \n4   abalone  \n5   abalone  \n6   abalone  \n7   abalone  \n8   abalone  \n9   abalone  \n10  abalone  \n11  abalone  \n12  abalone  \n13  abalone  \n14  abalone  \n15  abalone  \n16  abalone  \n17  abalone  \n18  abalone  \n19  abalone  \n20  abalone  \n21  abalone  \n22  abalone  \n23  abalone  \n24  abalone  \n25  abalone  \n26  abalone  \n27  abalone  \n28  abalone  \n29  abalone  \n30  abalone  \n31  abalone  \n32  abalone  \n33  abalone  \n34  abalone  \n35  abalone  \n36  abalone  \n37  abalone  \n38  abalone  \n39  abalone  \n40  abalone  \n41  abalone  \n42  abalone  \n43  abalone  ] is not valid under any of the given schemas\n        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chart({\n",
       "  data: [    Max_Iterations/Estimators  Split     Score       Hyperparameters  \\\n",
       "  0                           1   Test  0.482236  Best_Hyperparameters   \n",
       "  1                           2   Test  0.553529  Best_Hyperparameters   \n",
       "  2                           4   Test  0.578643  Best_Hyperparameters   \n",
       "  3                           8   Test  0.611336  Best_Hyperparameters   \n",
       "  4                          16   Test  0.633146  Best_Hyperparameters   \n",
       "  5                          32   Test  0.649362  Best_Hyperparameters   \n",
       "  6                          64   Test  0.652622  Best_Hyperparameters   \n",
       "  7                         128   Test  0.647394  Best_Hyperparameters   \n",
       "  8                         256   Test  0.647394  Best_Hyperparameters   \n",
       "  9                         512   Test  0.647394  Best_Hyperparameters   \n",
       "  10                       1024   Test  0.647394  Best_Hyperparameters   \n",
       "  11                       2048   Test  0.647394  Best_Hyperparameters   \n",
       "  12                       2100   Test  0.647394  Best_Hyperparameters   \n",
       "  13                       2200   Test  0.647394  Best_Hyperparameters   \n",
       "  14                       2300   Test  0.647394  Best_Hyperparameters   \n",
       "  15                       2400   Test  0.647394  Best_Hyperparameters   \n",
       "  16                       2500   Test  0.647394  Best_Hyperparameters   \n",
       "  17                       2600   Test  0.647394  Best_Hyperparameters   \n",
       "  18                       2700   Test  0.647394  Best_Hyperparameters   \n",
       "  19                       2800   Test  0.647394  Best_Hyperparameters   \n",
       "  20                       2900   Test  0.647394  Best_Hyperparameters   \n",
       "  21                       3000   Test  0.647394  Best_Hyperparameters   \n",
       "  22                          1  Train  0.484674  Best_Hyperparameters   \n",
       "  23                          2  Train  0.565532  Best_Hyperparameters   \n",
       "  24                          4  Train  0.588953  Best_Hyperparameters   \n",
       "  25                          8  Train  0.614279  Best_Hyperparameters   \n",
       "  26                         16  Train  0.653179  Best_Hyperparameters   \n",
       "  27                         32  Train  0.663983  Best_Hyperparameters   \n",
       "  28                         64  Train  0.668061  Best_Hyperparameters   \n",
       "  29                        128  Train  0.663552  Best_Hyperparameters   \n",
       "  30                        256  Train  0.663552  Best_Hyperparameters   \n",
       "  31                        512  Train  0.663552  Best_Hyperparameters   \n",
       "  32                       1024  Train  0.663552  Best_Hyperparameters   \n",
       "  33                       2048  Train  0.663552  Best_Hyperparameters   \n",
       "  34                       2100  Train  0.663552  Best_Hyperparameters   \n",
       "  35                       2200  Train  0.663552  Best_Hyperparameters   \n",
       "  36                       2300  Train  0.663552  Best_Hyperparameters   \n",
       "  37                       2400  Train  0.663552  Best_Hyperparameters   \n",
       "  38                       2500  Train  0.663552  Best_Hyperparameters   \n",
       "  39                       2600  Train  0.663552  Best_Hyperparameters   \n",
       "  40                       2700  Train  0.663552  Best_Hyperparameters   \n",
       "  41                       2800  Train  0.663552  Best_Hyperparameters   \n",
       "  42                       2900  Train  0.663552  Best_Hyperparameters   \n",
       "  43                       3000  Train  0.663552  Best_Hyperparameters   \n",
       "  \n",
       "     Algorithm  Dataset  \n",
       "  0        ANN  abalone  \n",
       "  1        ANN  abalone  \n",
       "  2        ANN  abalone  \n",
       "  3        ANN  abalone  \n",
       "  4        ANN  abalone  \n",
       "  5        ANN  abalone  \n",
       "  6        ANN  abalone  \n",
       "  7        ANN  abalone  \n",
       "  8        ANN  abalone  \n",
       "  9        ANN  abalone  \n",
       "  10       ANN  abalone  \n",
       "  11       ANN  abalone  \n",
       "  12       ANN  abalone  \n",
       "  13       ANN  abalone  \n",
       "  14       ANN  abalone  \n",
       "  15       ANN  abalone  \n",
       "  16       ANN  abalone  \n",
       "  17       ANN  abalone  \n",
       "  18       ANN  abalone  \n",
       "  19       ANN  abalone  \n",
       "  20       ANN  abalone  \n",
       "  21       ANN  abalone  \n",
       "  22       ANN  abalone  \n",
       "  23       ANN  abalone  \n",
       "  24       ANN  abalone  \n",
       "  25       ANN  abalone  \n",
       "  26       ANN  abalone  \n",
       "  27       ANN  abalone  \n",
       "  28       ANN  abalone  \n",
       "  29       ANN  abalone  \n",
       "  30       ANN  abalone  \n",
       "  31       ANN  abalone  \n",
       "  32       ANN  abalone  \n",
       "  33       ANN  abalone  \n",
       "  34       ANN  abalone  \n",
       "  35       ANN  abalone  \n",
       "  36       ANN  abalone  \n",
       "  37       ANN  abalone  \n",
       "  38       ANN  abalone  \n",
       "  39       ANN  abalone  \n",
       "  40       ANN  abalone  \n",
       "  41       ANN  abalone  \n",
       "  42       ANN  abalone  \n",
       "  43       ANN  abalone  ,     Max_Iterations/Estimators  Split     Score    Hyperparameters Algorithm  \\\n",
       "  0                           1   Test  0.485325  No_Regularization       ANN   \n",
       "  1                           2   Test  0.558503  No_Regularization       ANN   \n",
       "  2                           4   Test  0.583605  No_Regularization       ANN   \n",
       "  3                           8   Test  0.607264  No_Regularization       ANN   \n",
       "  4                          16   Test  0.638533  No_Regularization       ANN   \n",
       "  5                          32   Test  0.646394  No_Regularization       ANN   \n",
       "  6                          64   Test  0.645906  No_Regularization       ANN   \n",
       "  7                         128   Test  0.645906  No_Regularization       ANN   \n",
       "  8                         256   Test  0.645906  No_Regularization       ANN   \n",
       "  9                         512   Test  0.645906  No_Regularization       ANN   \n",
       "  10                       1024   Test  0.645906  No_Regularization       ANN   \n",
       "  11                       2048   Test  0.645906  No_Regularization       ANN   \n",
       "  12                       2100   Test  0.645906  No_Regularization       ANN   \n",
       "  13                       2200   Test  0.645906  No_Regularization       ANN   \n",
       "  14                       2300   Test  0.645906  No_Regularization       ANN   \n",
       "  15                       2400   Test  0.645906  No_Regularization       ANN   \n",
       "  16                       2500   Test  0.645906  No_Regularization       ANN   \n",
       "  17                       2600   Test  0.645906  No_Regularization       ANN   \n",
       "  18                       2700   Test  0.645906  No_Regularization       ANN   \n",
       "  19                       2800   Test  0.645906  No_Regularization       ANN   \n",
       "  20                       2900   Test  0.645906  No_Regularization       ANN   \n",
       "  21                       3000   Test  0.645906  No_Regularization       ANN   \n",
       "  22                          1  Train  0.486625  No_Regularization       ANN   \n",
       "  23                          2  Train  0.564506  No_Regularization       ANN   \n",
       "  24                          4  Train  0.587596  No_Regularization       ANN   \n",
       "  25                          8  Train  0.613439  No_Regularization       ANN   \n",
       "  26                         16  Train  0.657852  No_Regularization       ANN   \n",
       "  27                         32  Train  0.662788  No_Regularization       ANN   \n",
       "  28                         64  Train  0.662853  No_Regularization       ANN   \n",
       "  29                        128  Train  0.662853  No_Regularization       ANN   \n",
       "  30                        256  Train  0.662853  No_Regularization       ANN   \n",
       "  31                        512  Train  0.662853  No_Regularization       ANN   \n",
       "  32                       1024  Train  0.662853  No_Regularization       ANN   \n",
       "  33                       2048  Train  0.662853  No_Regularization       ANN   \n",
       "  34                       2100  Train  0.662853  No_Regularization       ANN   \n",
       "  35                       2200  Train  0.662853  No_Regularization       ANN   \n",
       "  36                       2300  Train  0.662853  No_Regularization       ANN   \n",
       "  37                       2400  Train  0.662853  No_Regularization       ANN   \n",
       "  38                       2500  Train  0.662853  No_Regularization       ANN   \n",
       "  39                       2600  Train  0.662853  No_Regularization       ANN   \n",
       "  40                       2700  Train  0.662853  No_Regularization       ANN   \n",
       "  41                       2800  Train  0.662853  No_Regularization       ANN   \n",
       "  42                       2900  Train  0.662853  No_Regularization       ANN   \n",
       "  43                       3000  Train  0.662853  No_Regularization       ANN   \n",
       "  \n",
       "      Dataset  \n",
       "  0   abalone  \n",
       "  1   abalone  \n",
       "  2   abalone  \n",
       "  3   abalone  \n",
       "  4   abalone  \n",
       "  5   abalone  \n",
       "  6   abalone  \n",
       "  7   abalone  \n",
       "  8   abalone  \n",
       "  9   abalone  \n",
       "  10  abalone  \n",
       "  11  abalone  \n",
       "  12  abalone  \n",
       "  13  abalone  \n",
       "  14  abalone  \n",
       "  15  abalone  \n",
       "  16  abalone  \n",
       "  17  abalone  \n",
       "  18  abalone  \n",
       "  19  abalone  \n",
       "  20  abalone  \n",
       "  21  abalone  \n",
       "  22  abalone  \n",
       "  23  abalone  \n",
       "  24  abalone  \n",
       "  25  abalone  \n",
       "  26  abalone  \n",
       "  27  abalone  \n",
       "  28  abalone  \n",
       "  29  abalone  \n",
       "  30  abalone  \n",
       "  31  abalone  \n",
       "  32  abalone  \n",
       "  33  abalone  \n",
       "  34  abalone  \n",
       "  35  abalone  \n",
       "  36  abalone  \n",
       "  37  abalone  \n",
       "  38  abalone  \n",
       "  39  abalone  \n",
       "  40  abalone  \n",
       "  41  abalone  \n",
       "  42  abalone  \n",
       "  43  abalone  ],\n",
       "  encoding: EncodingWithFacet({\n",
       "    color: Color({\n",
       "      shorthand: 'Split:N'\n",
       "    }),\n",
       "    column: Column({\n",
       "      shorthand: 'Hyperparameters:N'\n",
       "    }),\n",
       "    x: X({\n",
       "      axis: Axis({\n",
       "        title: 'Max_Iterations/Estimators'\n",
       "      }),\n",
       "      shorthand: 'Max_Iterations/Estimators:Q'\n",
       "    }),\n",
       "    y: Y({\n",
       "      scale: Scale({\n",
       "        domain: [0.0, 1.0]\n",
       "      }),\n",
       "      shorthand: 'Score:Q'\n",
       "    })\n",
       "  }),\n",
       "  mark: 'line',\n",
       "  selection: SelectionMapping({\n",
       "    selector001: SelectionDef({\n",
       "      bind: 'scales',\n",
       "      encodings: ['x', 'y'],\n",
       "      type: 'interval'\n",
       "    })\n",
       "  })\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(get_overfitting_curve(df_dict, dataset='abalone', algorithm='ANN')).mark_line().encode(\n",
    "    x=alt.X('Max_Iterations/Estimators:Q', axis=alt.Axis(title='Max_Iterations/Estimators')),\n",
    "    y=alt.Y('Score:Q', scale=alt.Scale(domain=[0.0, 1.0])),\n",
    "    color='Split:N',\n",
    "    column='Hyperparameters:N'\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Best number of Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best number using the GridSearchCV hyperparameters search\n",
    "\n",
    "* Best number using the OF parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colum with iteration numbers is one that ends with 'max_iter'\n",
    "iter_column = df_dict['ITER_base_ANN_OF_abalone'].filter(regex='_max_iter$').columns.values.tolist()\n",
    "# Sort by best test score and the locate the iterations column\n",
    "best_iterations = df_dict['ITER_base_ANN_OF_abalone'].sort_values(by='rank_test_score').loc[:, iter_column].values[0]\n",
    "best_iterations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ANN_abalone_LC_test', 'ANN_abalone_LC_train', 'ANN_abalone_reg', 'ANN_abalone_timing', 'ITERtestSET_ANN_abalone', 'ITERtestSET_ANN_OF_abalone', 'ITER_base_ANN_abalone', 'ITER_base_ANN_OF_abalone'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best number of iterations for best params and OF params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_iteration_number(df_dict, params='best'):\n",
    "    \"\"\"Pull the optimal number of iterations to run an \n",
    "    algorithm given either the 'best' hyperparams or \n",
    "    'overfitting' params\"\"\"\n",
    "    assert params in ['best', 'overfitting'], \\\n",
    "    \"params arg must be either 'best' or 'overfitting'\"\n",
    "    iterations_df_dict = {}\n",
    "    for key, df in df_dict.items():\n",
    "        # Check if it's the search across iteration \n",
    "        # number\n",
    "        if key.startswith('ITER_base'):\n",
    "            # Add to relevant dfs\n",
    "            iterations_df_dict[key] = df\n",
    "\n",
    "    for key, df in iterations_df_dict.items():\n",
    "        key_splits = key.split('_')\n",
    "        # Check if it's an overfitting df\n",
    "        if 'OF' in key_splits:\n",
    "            # Colum with iteration numbers is one that ends with 'max_iter'\n",
    "            iter_column = df.filter(regex='(_max_iter$|_estimators$|_iter$)').columns.values.tolist()\n",
    "            assert iter_column, \"\"\"No matching colum that ends with \"_max_iter\" or \"n_estimators\" \n",
    "            or \"n_iter\" found in file {}\"\"\".format(key)        \n",
    "            # Sort by best test score and the locate the iterations column\n",
    "            OF_best_iteration = df.sort_values(by='rank_test_score').loc[:, iter_column].values[0][0]\n",
    "        # Otherwise it's the best hyperparameters search\n",
    "        else:\n",
    "            # Colum with iteration numbers is one that ends with 'max_iter'\n",
    "            iter_column = df.filter(regex='(_max_iter$|_estimators$|_iter$)').columns.values.tolist()\n",
    "            #print(df)\n",
    "            assert iter_column, \"\"\"No matching colum that ends with \"_max_iter\" or \"n_estimators\" \n",
    "            or \"n_iter\" found in file {}\"\"\".format(key)           \n",
    "            # Sort by best test score and the locate the iterations column\n",
    "            best_iteration = df.sort_values(by='rank_test_score').loc[:, iter_column].values[0][0]\n",
    "    \n",
    "    if params=='best':\n",
    "        return best_iteration\n",
    "    elif params=='overfitting':\n",
    "        return OF_best_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best number of iterations for all datasets and algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cars', 'ANN'),\n",
       " ('cars', 'Boost'),\n",
       " ('cars', 'SVMLin'),\n",
       " ('cars', 'SVMRBF'),\n",
       " ('madelon', 'ANN'),\n",
       " ('madelon', 'Boost'),\n",
       " ('madelon', 'SVMLin'),\n",
       " ('madelon', 'SVMRBF')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "from analysis_helpers import *\n",
    "list(product(['cars', 'madelon'], \n",
    "                                       ['ANN', 'Boost', 'SVMLin', 'SVMRBF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_df_dict_from_algorithm_dataset('reports/output/', algorithm='SVM_Lin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_best_iters(fpath, datasets=None, algorithms=None, tidy=True):\n",
    "    from itertools import product\n",
    "    dataset_algorithm_pairs = list(product(datasets, algorithms))\n",
    "    \n",
    "    rows = []\n",
    "    for dataset_algorithm_combo in dataset_algorithm_pairs:\n",
    "        df_dict = get_df_dict_from_algorithm_dataset(fpath, \n",
    "                                                     dataset=dataset_algorithm_combo[0],\n",
    "                                                     algorithm=dataset_algorithm_combo[1])\n",
    "        overfitting_best_iteration = get_optimal_iteration_number(df_dict, params='overfitting')\n",
    "        best_iteration = get_optimal_iteration_number(df_dict, params='best')\n",
    "        rows.append([dataset_algorithm_combo[0], dataset_algorithm_combo[1], \n",
    "                    best_iteration, overfitting_best_iteration])\n",
    "    best_iterations = pd.DataFrame(rows, columns=['Dataset', 'Algorithm', \n",
    "                                                'Best_Params_Iterations', 'No_Regularization_Params'])\n",
    "    if tidy:\n",
    "        best_iterations = pd.melt(best_iterations, id_vars=['Dataset', 'Algorithm'],\n",
    "                                 var_name='Hyperparameters', value_name='Best_Number_of_Iterations/Estimators')\n",
    "        best_iterations['Hyperparameters'] = (best_iterations['Hyperparameters'].str.split('_')\n",
    "                                             .str.slice(0, -1)\n",
    "                                             .str.join('_')\n",
    "                                            )\n",
    "    return best_iterations\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_iter = pd.read_csv('reports/output/ITER_base_SVMLin_abalone.csv')\n",
    "# test_ter.\n",
    "# test_iter.filter(regex='(_max_iter$|_estimators$)').columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_number_of_iterations = get_all_best_iters('reports/output/', datasets=['cars', 'madelon'],\n",
    "algorithms=['ANN', 'Boost', 'SVMLin', 'SVMRBF'])\n",
    "\n",
    "best_number_of_iterations.to_csv('reports/output/best_number_of_iterations_by_data_algorithm_params_cars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_optimal_iteration_number(df_dict, params='overfitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename SVM Files to Seperate Easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename:\n",
      "reports\\output\\ITERtestSET_SVM_Lin_cars.csv\n",
      "To:\n",
      "reports\\output\\ITERtestSET_SVMLin_cars.csv\n",
      "\n",
      "\n",
      "Rename:\n",
      "reports\\output\\ITER_base_SVM_Lin_cars.csv\n",
      "To:\n",
      "reports\\output\\ITER_base_SVMLin_cars.csv\n",
      "\n",
      "\n",
      "Rename:\n",
      "reports\\output\\SVM_Lin_cars_LC_test.csv\n",
      "To:\n",
      "reports\\output\\SVMLin_cars_LC_test.csv\n",
      "\n",
      "\n",
      "Rename:\n",
      "reports\\output\\SVM_Lin_cars_LC_train.csv\n",
      "To:\n",
      "reports\\output\\SVMLin_cars_LC_train.csv\n",
      "\n",
      "\n",
      "Rename:\n",
      "reports\\output\\SVM_Lin_cars_reg.csv\n",
      "To:\n",
      "reports\\output\\SVMLin_cars_reg.csv\n",
      "\n",
      "\n",
      "Rename:\n",
      "reports\\output\\SVM_Lin_cars_timing.csv\n",
      "To:\n",
      "reports\\output\\SVMLin_cars_timing.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def file_search_and_replace(directory, search, replace, verbose=True):\n",
    "    \"\"\"Given a directory, search all filenames in it for the regex\n",
    "    pattern provided. If found, replace with the provided string \n",
    "    by renaming.\n",
    "    Set verbose=True to see which files are renamed\"\"\"\n",
    "    from pathlib import Path\n",
    "    import re\n",
    "    # Make path out of provided directory\n",
    "    directory_path = Path(directory)\n",
    "    # Search directory fielnames\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # If there's a pattern match\n",
    "        if re.search(search, filename):\n",
    "            # Create a new filename replacing the old pattern\n",
    "            new_fname = re.sub(search, replace, filename)\n",
    "            # Rename it\n",
    "            os.rename(directory_path / filename, directory_path / new_fname)\n",
    "            # If verbose print the renamed files\n",
    "            if verbose:\n",
    "                print(f'Rename:\\n{directory_path / filename}\\nTo:\\n{directory_path / new_fname}\\n\\n')\n",
    "            \n",
    "# # for filename in os.listdir(RESULTS_PATH):\n",
    "# #     if filename.startswith(\"SVM_Lin\"):\n",
    "# #         print(filename)\n",
    "# #         print('SVMLin'+filename.split('SVM_Lin')[1])\n",
    "# #         #os.rename(filename, filename[7:])\n",
    "\n",
    "file_search_and_replace('reports/output/', search='SVM_Lin_', replace='SVMLin_', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
