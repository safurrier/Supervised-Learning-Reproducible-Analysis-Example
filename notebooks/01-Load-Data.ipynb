{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ruamel.yaml as yaml\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "NO_CONFIG_ERR_MSG = \"\"\"No config file found. Root directory is determined by presence of \"config.yaml\" file.\"\"\"\n",
    "\n",
    "original_wd = os.getcwd()\n",
    "\n",
    "# Number of times to move back in directory\n",
    "num_retries = 10\n",
    "for x in range(0, num_retries):\n",
    "    # try to load config file\n",
    "    try:\n",
    "        with open(\"config.yaml\", 'r') as stream:\n",
    "            cfg = yaml.safe_load(stream)\n",
    "    # If not found move back one directory level\n",
    "    except FileNotFoundError:\n",
    "        os.chdir('../')\n",
    "        # If reached the max number of directory levels change to original wd and print error msg\n",
    "        if x+1 == num_retries:\n",
    "            os.chdir(original_wd)\n",
    "            print(NO_CONFIG_ERR_MSG)\n",
    "\n",
    "# Add directory to PATH\n",
    "path = os.getcwd()\n",
    "\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Madelon data and concat together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afurrier\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py:281: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->axis0] [items->None]\n",
      "\n",
      "  f(store)\n"
     ]
    }
   ],
   "source": [
    "madelon_train = pd.read_csv('data/raw/madelon/madelon_train.data.txt', header=None, sep=' ')\n",
    "madelon_test = pd.read_csv('data/raw/madelon/madelon_valid.data.txt', header=None, sep=' ')\n",
    "madelon_data = pd.concat([madelon_train, madelon_test], 0).astype(float)\n",
    "madelon_train_labels = pd.read_csv('data/raw/madelon/madelon_train.labels.txt',header=None,sep=' ')\n",
    "madelon_test_labels = pd.read_csv('data/raw/madelon/madelon_valid.labels.txt',header=None,sep=' ')\n",
    "madelon_labels = pd.concat([madelon_train_labels, madelon_test_labels], 0)\n",
    "madelon_labels.columns = ['Class']\n",
    "madelon_df = pd.concat([madelon_data, madelon_labels],1)\n",
    "madelon_df = madelon_df.dropna(axis=1,how='all')\n",
    "madelon_df.to_hdf('data/processed/datasets.hdf', 'madelon', complib='blosc', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>485.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>537.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>473.0</td>\n",
       "      <td>...</td>\n",
       "      <td>481.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483.0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>587.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>526.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>...</td>\n",
       "      <td>478.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>338.0</td>\n",
       "      <td>513.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>...</td>\n",
       "      <td>481.0</td>\n",
       "      <td>492.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>501.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480.0</td>\n",
       "      <td>491.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>417.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>476.0</td>\n",
       "      <td>...</td>\n",
       "      <td>480.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>469.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>484.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>402.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>...</td>\n",
       "      <td>479.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>504.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3      4      5      6      7      8      9  \\\n",
       "0  485.0  477.0  537.0  479.0  452.0  471.0  491.0  476.0  475.0  473.0   \n",
       "1  483.0  458.0  460.0  487.0  587.0  475.0  526.0  479.0  485.0  469.0   \n",
       "2  487.0  542.0  499.0  468.0  448.0  471.0  442.0  478.0  480.0  477.0   \n",
       "3  480.0  491.0  510.0  485.0  495.0  472.0  417.0  474.0  502.0  476.0   \n",
       "4  484.0  502.0  528.0  489.0  466.0  481.0  402.0  478.0  487.0  468.0   \n",
       "\n",
       "   ...      491    492    493    494    495    496    497    498    499  Class  \n",
       "0  ...    481.0  477.0  485.0  511.0  485.0  481.0  479.0  475.0  496.0     -1  \n",
       "1  ...    478.0  487.0  338.0  513.0  486.0  483.0  492.0  510.0  517.0     -1  \n",
       "2  ...    481.0  492.0  650.0  506.0  501.0  480.0  489.0  499.0  498.0     -1  \n",
       "3  ...    480.0  474.0  572.0  454.0  469.0  475.0  482.0  494.0  461.0      1  \n",
       "4  ...    479.0  452.0  435.0  486.0  508.0  481.0  504.0  495.0  511.0      1  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "madelon_df = pd.read_hdf('data/processed/datasets.hdf', key='madelon')\n",
    "\n",
    "madelon_df.to_csv('data/processed/madelon.csv', index=False)\n",
    "madelon_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Car Data and Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars_df = pd.read_csv('data/raw/cars/car.data.txt', header=None, \n",
    "#                       names=[\n",
    "# \"buying \", \n",
    "# \"maint\", \n",
    "# \"doors\", \n",
    "# \"persons\", \n",
    "# \"lug_boot\", \n",
    "# \"safety\",\n",
    "#                           'class'\n",
    "#                       ])\n",
    "# cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Changing to binary classification problem\n",
    "# # Acceptable, Good and Very Good all become the positive class 1\n",
    "# # Unacceptable is the negative class 0\n",
    "# cars_df['Class'] = cars_df['Class'].replace({'unacc':0,'acc':1,'vgood':2,'good':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars_df['doors'] = cars_df['doors'].replace({'5more':5}).apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_columns = pd.get_dummies(cars_df.select_dtypes(include='object')).rename(columns=lambda x: x.replace('-','_'))\n",
    "# cars_df = pd.concat([one_hot_columns, cars_df[['doors','class']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars_df.to_hdf('data/processed/datasets.hdf','cars',complib='blosc',complevel=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Income Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess with adult dataset\n",
    "# adult = pd.read_csv('data/raw/census-income/adult.data.txt',header=None)\n",
    "# adult.columns = ['age','employer','fnlwt','edu','edu_num','marital','occupation','relationship','race','sex','cap_gain','cap_loss','hrs','country','income']\n",
    "# # Note that cap_gain > 0 => cap_loss = 0 and vice versa. Combine variables.\n",
    "# adult['cap_gain_loss'] = adult['cap_gain']-adult['cap_loss']\n",
    "# adult = adult.drop(['fnlwt','edu','cap_gain','cap_loss'],1)\n",
    "# adult['income'] = pd.get_dummies(adult.income)\n",
    "\n",
    "# # Aggregate Countries to Higher Level Grouping\n",
    "# #http://scg.sdsu.edu/dataset-adult_r/\n",
    "# replacements = { 'Cambodia':' SE-Asia',\n",
    "#                 'Canada':' British-Commonwealth',\n",
    "#                 'China':' China',\n",
    "#                 'Columbia':' South-America',\n",
    "#                 'Cuba':' Other',\n",
    "#                 'Dominican-Republic':' Latin-America',\n",
    "#                 'Ecuador':' South-America',\n",
    "#                 'El-Salvador':' South-America ',\n",
    "#                 'England':' British-Commonwealth',\n",
    "#                 'France':' Euro_1',\n",
    "#                 'Germany':' Euro_1',\n",
    "#                 'Greece':' Euro_2',\n",
    "#                 'Guatemala':' Latin-America',\n",
    "#                 'Haiti':' Latin-America',\n",
    "#                 'Holand-Netherlands':' Euro_1',\n",
    "#                 'Honduras':' Latin-America',\n",
    "#                 'Hong':' China',\n",
    "#                 'Hungary':' Euro_2',\n",
    "#                 'India':' British-Commonwealth',\n",
    "#                 'Iran':' Other',\n",
    "#                 'Ireland':' British-Commonwealth',\n",
    "#                 'Italy':' Euro_1',\n",
    "#                 'Jamaica':' Latin-America',\n",
    "#                 'Japan':' Other',\n",
    "#                 'Laos':' SE-Asia',\n",
    "#                 'Mexico':' Latin-America',\n",
    "#                 'Nicaragua':' Latin-America',\n",
    "#                 'Outlying-US(Guam-USVI-etc)':' Latin-America',\n",
    "#                 'Peru':' South-America',\n",
    "#                 'Philippines':' SE-Asia',\n",
    "#                 'Poland':' Euro_2',\n",
    "#                 'Portugal':' Euro_2',\n",
    "#                 'Puerto-Rico':' Latin-America',\n",
    "#                 'Scotland':' British-Commonwealth',\n",
    "#                 'South':' Euro_2',\n",
    "#                 'Taiwan':' China',\n",
    "#                 'Thailand':' SE-Asia',\n",
    "#                 'Trinadad&Tobago':' Latin-America',\n",
    "#                 'United-States':' United-States',\n",
    "#                 'Vietnam':' SE-Asia',\n",
    "#                 'Yugoslavia':' Euro_2'}\n",
    "# # Strip whitespace\n",
    "# adult['country'] = adult['country'].str.strip()\n",
    "\n",
    "# # Replace Countries, unemployment in employer column, and combine Husband and Wife to Spouse\n",
    "# adult = adult.replace(to_replace={'country':replacements,\n",
    "#                                   'employer':{' Without-pay': ' Never-worked'},\n",
    "#                                   'relationship':{' Husband': 'Spouse',' Wife':'Spouse'}})    \n",
    "# adult['country'] = adult['country'].str.strip()\n",
    "\n",
    "# # Strip whitespace in string columns\n",
    "# for col in ['employer','marital','occupation','relationship','race','sex','country']:\n",
    "#     adult[col] = adult[col].str.strip()\n",
    "    \n",
    "# # One hot encode data and rename columns to underscores to allow for \n",
    "# # Pandas column accessors\n",
    "# adult = pd.get_dummies(adult)\n",
    "# adult = adult.rename(columns=lambda x: x.replace('-','_'))\n",
    "\n",
    "# adult.to_hdf('data/processed/datasets.hdf','adult',complib='blosc',complevel=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Abalone Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1447\n",
       "0    1407\n",
       "1    1323\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = [\"Sex\",\n",
    "\"Length\",\n",
    "\"Diameter\",\n",
    "\"Height\",\n",
    "\"Whole weight\",\t\n",
    "\"Shucked weight\",\n",
    "\"Viscera weight\",\n",
    "\"Shell weight\",\n",
    "\"Rings\"]\n",
    "\n",
    "abalone_df = pd.read_csv('data/raw/abalone/abalone.txt', names=column_names)\n",
    "\n",
    "# Create classification problem based on Rings, which are a function of age (Age = 1.5 + Rings)\n",
    "#abalone_df['Class'] = np.where(abalone_df['Rings'] > 9, 1, 0) Binary Classification\n",
    "\n",
    "# Multilabel classification\n",
    "# Infants, Most prevalent age (9-10) before harvesting\n",
    "# Full adults\n",
    "abalone_df['Class'] = pd.cut(abalone_df['Rings'], bins=[-1, 8.9, 10.1, 100], labels=[0, 1, 2]).astype(int)\n",
    "abalone_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode gender and concat together\n",
    "abalone_with_sex_df = abalone_df\n",
    "abalone_df = pd.concat([pd.get_dummies(abalone_df['Sex'], prefix='Sex'), \n",
    "                       abalone_df.drop(columns=['Sex', 'Rings'], axis=1)], axis=1)\n",
    "\n",
    "# Export data\n",
    "abalone_df.to_hdf('data/processed/datasets.hdf','abalone', format='table', complib='blosc',complevel=9)\n",
    "abalone_df.to_csv('data/processed/abalone.csv', index=False)\n",
    "abalone_with_sex_df.to_csv('data/processed/abalone_not_one_hot_encoded.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml7641-assignment-one",
   "language": "python",
   "name": "ml7641-assignment-one"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
